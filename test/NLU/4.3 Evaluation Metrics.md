
|                             | Positive class(response) | Negative Class(Response) |
| --------------------------- | ------------------------ | ------------------------ |
| Positive class (Reference)  | True Positive(TP)        | False Positive(FN)       |
| Negative class (Reference ) | False Negative(FN)       | True Negatives(TN)       |

### Accuracy
It is ration of matches between the response and reference to the total number of items.
![[Screenshot 2024-02-27 at 14.57.20.png]]
This is only suitable for **balanced data**! Look at the example above: it shows that the model is doing quite well, but it doing well in identifying the negative classes!

### Precision, Recall, F-score:
Precision: proportion of labelled items that are correct!
$$Precision = \frac{TP}{TP + FP}$$
Recall: proportion of correct items that were labelled.
$$Precision = \frac{TP}{TP + FN}$$
F-Score: weighted harmonic mean. The bigger the values of $\beta$ mean more emphasis on recall.
$$F_\beta = \frac{(\beta^2 +1)PR}{((\beta^2P)R}, \beta=1 \rightarrow F_1= \frac{2PR}{P+R} $$

>Remark: Support
>This figure tells us  the number of instances in the reference in the gold standard. 

F-Score can be used in:
- sequence classification tasks 
- pairwise sequence classification tasks 
- span-based classification
- span-based relation classification inter-annotator agreement
- sequence labelling tasks, e.g., NER 
- span-based identification (or span extraction)
### F-score in NER:
![[Screenshot 2024-02-27 at 16.10.55.png]]

### F-Scores for evaluating span extraction
![[Screenshot 2024-02-27 at 16.16.11.png]]

### EM for evaluating span extraction
![[Screenshot 2024-02-27 at 16.21.37.png]]
## Summmary
![[Screenshot 2024-02-27 at 16.21.58.png]]

# Comparing Categories of Metrics
How do now calculate the performance `over multiple categories`?
- Macro-Averaging
- Weighted macro-averaging
- Micro-averaging 

![[Screenshot 2024-02-27 at 15.42.41.png]]
![[Screenshot 2024-02-27 at 15.43.55.png]]
![[Screenshot 2024-02-27 at 15.45.28.png]]

Which one to use for my task?
- If all tasks are equally important: macro-averaging 
- If majority class is more important: weighted macro-averaging
- otherwise: micro-averaging 

Example: Hate Speech
Micro-averaging for hate speech detection
Important class: hate, majority class: non-hate

<iframe src="https://video.manchester.ac.uk/embedded/ffffffff-e8db-53e5-0000-018dc059b100" width="660" height="380" style="border:none; overflow: hidden;" scrolling="no"  start=24 webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

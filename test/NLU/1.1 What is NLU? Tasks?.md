NLP converts unstructured data into a structured(and more machine readable form) like using tokenisation, lemmatisation, stemming, NER.

NLU determines the **intended meaning** of natural-language expressions; enables machines to recognise **variations** in language. 

NLG[Natural Language Generation] produces natural language expressions.

For example:
A chatbot can be made using NLP to recognise names, dates, specific topics. NLU helps to make the conversation **more natural** e.g. through correct interpretation of NL expressions.

Cues from the speech are also very important to consider. There are different modalities, but for text generating the focus will be on natural language generation.

How can we use Natural Language Generation(NLG)?
$\square$  It is highly relevant and can support the development of NLU.
$\square$  Help generating **synthetic** training data for NLU.
$\square$  We use seq2seq translation [End of course]

What are the typical tasks? 
1) Sequence classification
2) Pairwise sequence classification
3) Sequence labelling
4) Span-based operations
### Sequence classification
This is where the input is a sequence[a sequence of tokens], and it has to be classified into a class. The classes are pre-defined and usually a finite set of them.
![[Screenshot 2024-02-01 at 11.19.27.png]]
### Pairwise Sequence classification
This is where you have two sequences and you have to classify into a class, according to the relationship that holds between them.
![[Screenshot 2024-02-01 at 11.21.56.png]]

### Sequence Labelling
This is classification at the level of tokes; also known as **token classification**. 
![[Screenshot 2024-02-05 at 16.26.54.png]]
In this example above, it is useful to know that a sequence of tokens makes a **unit**- this is useful for NER. Some units are the same as token level- POS tagging. Therefore you can use a different labelling scheme depending on your problem.
### Span-based operations
This is a continuous sequence of tokens, but the sequence doesn't necessarily have to a document or a full sentence - these are called **spans**.

Input: A sequence
1) All possible spans are generated
2) Total number of spans are $= \frac{T(T+1)}{2}$ , which includes all n-grams up to size $T$, which is the set to the total number of tokens in the given sequence.
e.g. Jane Villanueva of United Airlines Holdings arrived.
This has 28 possible spans since $T=7$, which includes all the n-grams from 1-7 

There are 3 different types of spanning:
1) Identification/Binary classification
2) Regular classification 
3) Relation classification
#### Identification/ Binary classification
This is where you are identifying spans of interest using binary classification. This is usually a 0/1.
![[Screenshot 2024-02-01 at 11.42.29.png]]
#### Regular classification
This is where you are classifying a span based on some pre-defined labels.
![[Screenshot 2024-02-01 at 11.44.56.png]]
This is same as NER, but it can provide additional benefits compared to NER. We get **embedded entities**- like United Airlines, and United Airlines Holdings. So seq2seq classification may not get United Airlines as being a company name.

#### Relation classification
classifying pre-defined relations between spans.
![[Screenshot 2024-02-05 at 18.11.18.png]]


# NLU Tasks
1) Sentiment analysis: identify the sentiment[happy, sad, neutral] of it. This is `sequence classification`.
2) Emotion recognition:  identify the type of emotion contained depending on the label used. This is `sequence classification`.
3) Hate Speech detection: to determine whether the text contains hate speech[religion-based, gender-based, racist]. This is `sequence classification`
4) Natural Language Inference[NLI] : You are given two pieces of text: premise and hypothesis. The idea is to use the premise to check if the hypothesis is true(entailment), false(contradiction), or neutral. This is `pairwise sequence classification.`
5) Paraphrase classification: Given two pieces of test, the task is to determines if one is a paraphrase of another. This is `pairwise sequence classification.`

	 A variation of this is **Semantic Textual Similarity(STS)**, which is to measure the degree the similarity between two pieces of text.

6)  Named Entity Recognition[NER] : Given a sequence, the task is to identify a subsequence corresponding to semantic labels of interest. This can done using `sequence labelling` & `span-based classification.`
7)  Entity Linking: Given a sequence, to link the subsequence to its standard/lexical/canonical form in the vocabulary/lexicon. This can be done using `pairwise sequence classification`, whether the word used in the text is the same as the standard named entity.  It can be done using `span-based classification`, this would be multi-class classification. So you would have lots of classes from the standard named entity form, and classify all the spans.
8)  Semantic Role Labelling[SRL] : Given a sequence, the task is to identify the **predicate-argument structure** to the questions to: "who did what to whom where and why?" This can be done using `sequence labelling` and `span-based classification`.
![[Screenshot 2024-02-06 at 14.55.56.png]]
9) Relation Extraction: Given two subsequences[two spans], the relation type that holds between them. This can be done using `span-based relation classification.`
![[Screenshot 2024-02-06 at 14.52.38.png]]
10) Coreference Resolution: Given two subsequences[two spans], the task is to see if the two spans refer the same entity. This is done using `span-based relation classificaition.`
![[Screenshot 2024-02-06 at 14.55.10.png]]


# Multi-Problem Tasks
There are few tasks:
1) Aspect-Based Sentiment Analysis
2) Fact Verification
3) Argument Mining
4) Question-Answering 
5) Event Extraction
### Aspect-Based Sentiment Analysis:
This is a variation of sentiment analysis. The task is to identify the target of the sentiment, and also the aspect of it too.

> Sentence: Horrible services. The room was dirty and unpleasant. 
> Target: room
> aspect: cleanliness (out of categories: price, location, comfort.)

We do `span-based classificication` to find the target. The target is usually a token from the sequence.
We do `span-based classificication` to find the aspect. This usually belongs to a pre-set labels, and it might not appear in the sequence at all.
Then we do `span-based relation classification`.



### Fact Verification 
Given a piece of text, determine whether the information is true. We can usually break it down into subproblems, and deal with that way.

Problem-1: To determine whether a piece of text is worth fact checking. Not all the sentence are relevant to the fact. We want to identify all the sentences that are worth fact checking. 
Solution: We can do `sequence classification`, where we would check each sentence is worth fact checking or not. Or, you can treat it as a `span-based identification` problem, and answering the question is it worth fact checking or not.

Problem-2: Then we to find the pieces of text that are relevant to the given claim. They're talking about the same information, event etc. This is also known as **evidence retrival.**
Solution: We can do a `pairwise sequence classification`. You can present the model the claim, and the other hand present a piece of relevant to check if they're relevant to it.

Problem-3: Determine if a piece of text contain information that is supported or refuted by the evidence.
Solution:  You can use `pairwise sequence classification` to ask the question whether the evidence supports or refutes the claim.

### Argument Mining
Given a piece of text/multiple texts, to identify the argumentative structures:  extract/mine the claim and the premises that supports and refutes it. 

Sub-Problem-1: **Argument Component Identification**: which is identifying the claims and premises.
Solution: We can consider it as `span-based classification` problem, and identify all the claims and premises.

Sub-Problem-2: **Argument Relation Classification:** We need to categorise all the premises whether they support or refute the claim.
Solution: We can consider it as `span-based relation classification`, to identify if its a supporting or refuting relation.

### Question Answering(Extractive)
Given two pieces of text, a passage and question, to identify the span of the text that answers the question. 

This can be solved using `pairwise,span-based identification.`  So we want to identify the spans are relevant to the question.

### Event Extraction
Given a sequence and a list of entities, the task is to identify  **event triggers** and the **event participants**.
![[Screenshot 2024-02-06 at 18.56.06.png]]
So, Miller and Palestine gunmen are given, and we want to identify the event trigger which is `hit` in the case. Then find all the event participants, as not all the names are taking part.

Sub-Problem-1: **Event Trigger Detection** identify the word that denotes the event and its type. So, it isn't just finding out the trigger word, but also classifying the trigger word.
Solution: We use `span-based classificaiton` as we have different spans, and we classify the span denotes an event, and what kind of event that is. We can also use `sequence labelling`.

Sub-Problem-2: **Event Participation Identification***: To find the relationship that holds between the named entity, and the event trigger.
Solution: We use `span-based relation classification`.












We use DNN to solve image/vision related tasks, and they're very good at solving this problem. At first, they used simple NN, and **AlexNet** was the first one that was developed using **Convolutional** NN. Then **VGG** was developed by Oxford, and also RestNet.
![[Screenshot 2024-02-24 at 21.38.36.png]]


# Read it!
![[Screenshot 2024-02-24 at 21.42.05.png]]


# Neural Network
It is network consisting of interconnected nodes. You have at least an input layer, and one hidden layer; this connects to the output layer. The **connections** or **parameters** are initially randomly allocated, and there are algorithms to reduce the error.
![[Screenshot 2024-02-24 at 21.48.03.png]]

### Shallow vs Deep NN(topology)
Shallow:
- Simple Perceptron(2 Layers)
- MLP (3 Layers)
Deep Neural Network:
- CNN 
- RNN
- Transformers
- Other types: GAN,...
- Celebrities: AlexNet(CNN), VGG16(CNN), ResNet50(CNN), BERT, ViT, GBT
## History of NNet
![[Screenshot 2024-02-24 at 21.56.02.png]]
- Electron Brain: McCulloch & Pitts developed the idea of a single neuron
- Perceptron: Rosenblatt developed the idea.
- XOR: Minsky and Papert - since the shallow NN couldn't solve the XOR being solved.
- Back-propagation was  invented.
- DNN with the development of CNN.

# FeedForward Neural network
This are simple networks that that 1 hidden layer called a perceptron, or many hidden layers which is a multilayer perceptron.
![[Screenshot 2024-02-24 at 22.02.51.png]]
When training the parameters, we are trying to find the best weights.
- To minimise the error $E$ of output $y$ with respect to target $t$ by iteratively modifying the weights.
- We use **backpropagation** to adjust the weights depending on the output, and we use **gradient descent** to find the error.
![[Screenshot 2024-02-24 at 22.11.16.png]]

## Stochastic Gradient Descent
We calculate the gradient at each iteration. This causes it to go towards the local minimum. It will bounce around and there are different trajectories highlighted as well.
![[Screenshot 2024-02-24 at 22.16.29.png]]
This also means that the single stimulus can have high error and not a good approximator. It could get struck at a point of inflection, or a local minimum. To encourage further **exploration**(to find alternative solutions) we could use **mini-batch gradient descent.** 

## Training!
There are 3 types of data: training, validation and testing.

**Validation data**  is a set of stimuli set aside. It is used to test the model the models performance. It is there to check that the model isn't overfitted to the training data, but it can also predict unseen data.

**Testing data** is another set of stimuli set aside and it is never seen by the model. Again it is there to check overfitting.

**Epoch**: each stimuli has been trained with once.

Training Terminology
**Accuracy**: for classification problems e.g. binary accuracy, categorical accuracy, sparse categorical accuracy, top k categorical accuracy. 
**Error Loss**: difference between predicted and observed values, e.g. MSE, RMSE, MAE, MAPE, MSLE
**Categorical Loss**: cross entropy loss for classification tasks - binary cross entropy, categorical cross-entropy, sparse categorical.

**Hyperparamterer**
- Network Size: number of hidden neurones, convolution and pooling parameters
- Training parameters: learning rate
- Optimisation Methods: Adam, RMSProp, AdaGrad
- Overfitting: Regularisation strength, dropout probability. 
### Preventing Overfitting:
Use **Dropout**:
Each neuron is inactive with some **random probability** during each training mini-batch. Forces the network to be accurate even in the absence of certain neurones. It forces the neurones to pay **attention** to the shape and information rather than memorising the data.
![[Screenshot 2024-02-24 at 22.33.26.png]]

**Data Augmentation**:
We can extend the training data set- this helps to reduce overfitting and improves generalisation.
- Generate new images with **noise**, shifting position, flipping
- Data distorsion(LeNet-5)
- New images translations and horizontal reflections, extracting random 224x224 patches(AlexNet)
- Altering intensities or RGB channels(AlexNet)

We use bench-marking dataset: MNIST.
![[Screenshot 2024-02-24 at 23.07.40.png]]![[Screenshot 2024-02-24 at 23.08.11.png]]


# CNN
The old way is toe human-defined features like how many edges e.g. a list of features and didn't see the features- an example is SIFt.

LeNet was the first convolutional neural network. 


Chunking is the process of grouping tokens that have a group of words that have a specific grammatical purpose. 

A $\mathbf{noun}$ $\mathbf{phrase}$  is a phrase which has a noun, as its head, which performs the same function as other words.
	e.g. *This sentence* contains *two noun phrases*
A $\mathbf{verb}$ $\mathbf{phrase}$ is a syntactic unit composed of at least one verb and its dependents
	David *gave Mary a book*

## Noun Phrases
![[Screenshot 2023-11-03 at 15.16.31.png]]
	This is a noun phrase which is about flights. That's the central noun in this NP - it is called the head.
	**pre-modifiers** come before the head, and **post-modifiers** come after the head
	So, a NP contains a determiner and then a nominal which is composed of the pre-modifiers, head, and post-modifiers.

Determiners can be:
- Simple lexical items: the, this, a, e.g. a car
- Or simple possessives like Mehedi's car
- Or complex version Mehedi's sister's son's car

Pre-modifiers:
- Quantifiers: three cars
- Adjectives: large cars
- Ordering pre-modifiers: three large cars? large three cars?

Post-modifiers like from Seattle, arriving before noon, that serves breakfast.

So, there are many rules to model the structure of NPs. You may need to create additional constraints depending if the noun is singular or plural. So, you would to create these constraints which usually leads to **over-generate**.

## Verb Phrases
Verb Phrases consist of a *head* verb along with 0 or more following arguments. 
![[Screenshot 2023-11-03 at 15.31.39.png]]
	We can **subcategorise** the verbs according to a set of VP rules, like the number of arguments required, which is the constraint. This can be done using context-free grammer.

#### What's the alternative? TreeBanks
The idea: instead of paying linguistic to write a grammer, pay the to annotate real sentences with parse trees. 
	This usually requires a detailed annotated guidelines that provide a POS tag-set, and how to deal with particular grammer.
Then uses annotated data to learn the rules. We usually use a right parser tree.
A widely use treebank is Penn TreeBank.

Then we can develop a probabilistic context free grammer, where each production rule has a probability.
![[Screenshot 2023-11-03 at 15.42.48.png]]

### Probabilistic CFGs
Each rule $A \longrightarrow a$ is assigned a probability $P(a|A)$ 
	Note: the sum over all A is equal to 1
Easiest way to create a PCFG from a treebank is to use MLE:
	$\square$  Count all the occurrences of $A \longrightarrow a$ in the tree bank.
	$\square$  Divide by the count of all the rules whose LHS is $A$ to get $P(a|A)$ 
Chunking is now probabilistic, where production probabilities are used to non-deterministically select production for rewriting a given non-terminal. 
![[Screenshot 2023-11-03 at 15.50.51.png]]

![[Screenshot 2023-11-03 at 15.51.21.png]]

